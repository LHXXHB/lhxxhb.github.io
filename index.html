<!doctype html>
<html>
  <head>
    <title>Dapeng Hu's Homepage</title>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <meta name="description" content="Dapeng Hu is a Ph.D. Student at National University of Singapore. His research lies in Transfer Learning, Computer Vision.">
    <meta name="keywords" content="Dapeng Hu">

    <meta property="og:type" content="website">
    <meta property="og:title" content="Dapeng Hu's Homepage">
    <meta property="og:site_name" content="Dapeng Hu's Homepage">
    <meta property="og:description" content="Dapeng Hu is a Ph.D. Student at National University of Singapore. His research lies in Transfer Learning, Computer Vision.">
    <meta property="og:locale" content="default">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Dapeng Hu's Homepage">
    <meta name="twitter:description" content="Dapeng Hu is a Ph.D. Student at National University of Singapore. His research lies in Transfer Learning, Computer Vision.">


    <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" integrity="sha384-gfdkjb5BdAXd+lj+gudLWI+BXq4IuLW5IT+brZEZsLFm++aCMlF1V92rMkPaX4PP" crossorigin="anonymous">
    <link rel="stylesheet" href="stylesheets/academicons/css/academicons.min.css"/>


  </head>
  <body>
    <div class="wrapper">
      <header>
        <center>
        <a href="#" class="image avatar"><img src="images/avatar.jpg" alt="" onContextMenu="return false" /></a>
        <h1><strong>Dapeng Hu</strong><br></h1>
            National University of Singapore<br>
            lhxxhb15 (at) gmail.com<br>
            [<a href="https://scholar.google.com/citations?user=wv9HjA0AAAAJ&hl=en" target="_blank" rel="noopener">Google Scholar</a>]
            <br>
        </center>
      </header>
      <section>
          <h1 id="biography"><a href="#biography" class="headerlink" title="biography"></a>About Me</h1>

              <p>I am a Ph.D. student in Electrical and Computer Engineering at <a href="http://nus.edu.sg/" target="_blank" rel="noopener">National University of Singapore</a>, supervised by <a href="https://sites.google.com/site/jshfeng/" target="_blank" rel="noopener">Prof. Jiashi Feng</a> and <a href="https://sites.google.com/site/sitexinchaowang/" target="_blank" rel="noopener">Prof. Xinchao Wang</a>. My research lies in transfer learning and computer vision, specifically in the following topics:</p>
              <ul>
              <li> Domain adaptation and semi-supervised learning: How to leverage unlabeled data for training a task-specific model? 
              <li> Representation learning and self-supervised learning: How to pre-train a generalized representation model?
              <li> Model-based transfer learning and fine-tuning: How to transfer the knowledge in a pre-trained source model to a given domain or task? 
              <li> Large-scale empirical studies on deep learning models: How to observe, understand, and explain the behavior of deep neural networks? 
              </ul>
                  
        
        <h1 id="education"><a href="#education" class="headerlink" title="education"></a>Education</h1>

              <ul>
              <li><p style="float:right">Jan 2019 - Present</p><education>Ph.D. in Electrical and Computer Engineering</education>
                <br>
                National University of Singapore
                <br>
                GPA: 4.75/5.0
                <br>
                Advisor: <a href="https://sites.google.com/site/jshfeng/" target="_blank" rel="noopener">Prof. Jiashi Feng</a> & <a href="https://sites.google.com/site/sitexinchaowang/" target="_blank" rel="noopener">Prof. Xinchao Wang</a>
              </ul>
        
              <ul>
              <li><p style="float:right">Aug 2013 - Jun 2017</p><education>B.Sc. in Electronic Information Science and Technology</education>
                <br>
                Nanjing University
                <br>
                GPA: 90/100
              </ul>

          <h1 id="publications"><a href="#publications" class="headerlink" title="publications"></a>Publications</h1>

                <ul>
                <li><papertitle>UMAD: Universal Model Adaptation under Domain and Category Shift</papertitle>
                  <br>
                  Jian Liang, <strong>Dapeng Hu*</strong>, Jiashi Feng, & Ran He.
                  <br>
                  Under Review, <strong>Arxiv 2021</strong>.
                  <br>
                  [<a href="https://arxiv.org/pdf/2112.08553.pdf" target="_blank" rel="noopener">PDF</a>]                
                </li>
                </ul>

                <ul>
                <li><papertitle>DINE: Domain Adaptation from Single and Multiple Black-box Predictors</papertitle>
                  <br>
                  Jian Liang, <strong>Dapeng Hu</strong>, Jiashi Feng, & Ran He.
                  <br>
                  In Computer Vision and Pattern Recognition, <strong>CVPR 2022</strong>.
                  <br>
                  [<a href="https://arxiv.org/pdf/2104.01539.pdf" target="_blank" rel="noopener">PDF</a>]                
                </li>
                </ul>


                <ul>
                  <li><papertitle>How Well Does Self-Supervised Pre-Training Perform with Streaming Data?</papertitle>
                    <br>
                    <strong>Dapeng Hu</strong>, Shipeng Yan*, Qizhengqiu Lu, Lanqing Hong, Hailin Hu, Yifan Zhang, Zhenguo Li, Xinchao Wang, & Jiashi Feng.
                    <br>
                    In International Conference on Learning Representations, <strong>ICLR 2022</strong>. 
                    <br>
                    (The shorter version was presented in NeurIPS 2021 Workshop on ImageNet: Past, Present, and Future, <strong>NeurIPS ImageNet PPF 2021</strong>).
                    <br>
                    <br>
                    [<a href="https://openreview.net/pdf?id=EwqEx5ipbOu" target="_blank" rel="noopener">PDF</a>]                
                  </li>
                  </ul>

                <ul>
                <li><papertitle>Adversarial Domain Adaptation with Prototype-based Normalized Output Conditioner</papertitle>
                  <br>
                  <strong>Dapeng Hu</strong>，Jian Liang*, Qibin Hou, Hanshu Yan, & Yunpeng Chen.
                  <br>
                  In IEEE Transactions on Image Processing, <strong>TIP 2021</strong>.
                  <br>
                  [<a href="https://arxiv.org/abs/2003.13274" target="_blank" rel="noopener">PDF</a>]                
                </li>
                </ul>

                <ul>
                <li><papertitle>Source Data-absent Unsupervised Domain Adaptation through Hypothesis Transfer and Labeling Transfer</papertitle>
                  <br>
                  Jian Liang, <strong>Dapeng Hu</strong>，Yunbo Wang, Ran He, & Jiashi Feng.
                  <br>
                  In IEEE Transactions on Pattern Analysis and Machine Intelligence, <strong>TPAMI 2021</strong>.
                  <br>
                  [<a href="https://arxiv.org/pdf/2012.07297.pdf?ref=https://githubhelp.com" target="_blank" rel="noopener">PDF</a>]                
                </li>
                </ul>

                <ul>
                <li><papertitle>No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data</papertitle>
                  <br>
                  Mi Luo, Fei Chen, <strong>Dapeng Hu</strong>, Yifan Zhang, Jian Liang, & Jiashi Feng.
                  <br>
                  In Advances in Neural Information Processing Systems, <strong>NeurIPS 2021</strong>.
                  <br>
                  [<a href="https://arxiv.org/pdf/2106.05001.pdf" target="_blank" rel="noopener">PDF</a>]                
                </li>
                </ul>

                <ul>
                <li><papertitle>Unleashing the Power of Contrastive Self-Supervised Visual Models via Contrast-Regularized Fine-Tuning</papertitle>
                  <br>
                  Yifan Zhang, Bryan Hooi, <strong>Dapeng Hu</strong>, Jian Liang, & Jiashi Feng.
                  <br>
                  In Advances in Neural Information Processing Systems, <strong>NeurIPS 2021</strong>.
                  <br>
                  [<a href="https://arxiv.org/pdf/2102.06605.pdf" target="_blank" rel="noopener">PDF</a>]                
                </li>
                </ul>

                <ul>
                <li><papertitle>Domain Adaptation with Auxiliary Target Domain-Oriented Classifier</papertitle>
                  <br>
                  Jian Liang, <strong>Dapeng Hu</strong>, & Jiashi Feng.
                  <br>
                  In Computer Vision and Pattern Recognition, <strong>CVPR 2021</strong>.
                  <br>
                  [<a href="https://arxiv.org/pdf/2007.04171.pdf" target="_blank" rel="noopener">PDF</a>]                
                </li>
                </ul>

                <ul>
                <li><papertitle>Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation</papertitle>
                  <br>
                  Jian Liang, <strong>Dapeng Hu</strong>, & Jiashi Feng.
                  <br>
                  In International Conference on Machine Learning, <strong>ICML 2020</strong>.
                  <br>
                  [<a href="https://arxiv.org/pdf/2002.08546.pdf" target="_blank" rel="noopener">PDF</a>]                
                </li>
                </ul>

              <ul>
              <li><papertitle>A Balanced and Uncertainty-aware Approach for Partial Domain Adaptation</papertitle>
                <br>
                Jian Liang, Yunbo Wang, <strong>Dapeng Hu</strong>, Ran He, & Jiashi Feng.
                <br>
                In European Conference on Computer Vision, <strong>ECCV 2020</strong>.
                <br>
                [<a href="https://arxiv.org/pdf/2003.02541.pdf" target="_blank" rel="noopener">PDF</a>]                
              </li>

              (* denotes equal-first contribution.)
              </ul>

        <h1 id="service"><a href="#service" class="headerlink" title="service"></a>Professional Service</h1>
              <ul>
              <li><strong>Journal Reviewer</strong>: TMLR 2022.
              <br>
              <li><strong>Conference Reviewer</strong>: ICML 2021-2022, NeurIPS 2021-2022, ICLR 2022, CVPR 2022.
              <br>
              <li><strong>Workshop Reviewer</strong>: NeurIPS ImageNet PPF 2021.
              <br>
              <li><strong>Teaching Assistant</strong>: EE6934 Deep Learning (Advanced), EE5934 Deep Learning, EE4704 Image Processing and Analysis, EE2028 Microcontroller Programming and Interfacing.
              </ul>
        
        
          <br>

      </section>

      <footer>
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=a1a09e&w=a&t=n&d=nkv-j4iQDArGPf1C3rjKpS8g01mWYpxlRqAYpt5-OLU&co=ffffff&cmn=f2bd01&cmo=91a67d&ct=95a10a'></script>
      </footer>
    </div>
  </body>
</html>
